{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0vAyv6fzSOLyzNrNj0ozT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/putrinahampun/PreparationForTFDSExam/blob/main/TensorflowExam/Problem3TFD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWvpnu2u0cSP",
        "outputId": "01c68a25-5eda-47dd-a3d1-4c9988fd1bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31367 files belonging to 43 classes.\n",
            "Found 7842 files belonging to 43 classes.\n",
            "Epoch 1/10\n",
            "981/981 [==============================] - 36s 35ms/step - loss: 1.1855 - accuracy: 0.6934 - val_loss: 0.4191 - val_accuracy: 0.8949\n",
            "Epoch 2/10\n",
            "981/981 [==============================] - 34s 35ms/step - loss: 0.2767 - accuracy: 0.9315 - val_loss: 0.2372 - val_accuracy: 0.9425\n",
            "Epoch 3/10\n",
            "981/981 [==============================] - 35s 36ms/step - loss: 0.1522 - accuracy: 0.9620 - val_loss: 0.1793 - val_accuracy: 0.9579\n",
            "Epoch 4/10\n",
            "981/981 [==============================] - 35s 36ms/step - loss: 0.1072 - accuracy: 0.9718 - val_loss: 0.1523 - val_accuracy: 0.9614\n",
            "Epoch 5/10\n",
            "981/981 [==============================] - 35s 35ms/step - loss: 0.0801 - accuracy: 0.9795 - val_loss: 0.1429 - val_accuracy: 0.9691\n",
            "Epoch 6/10\n",
            "981/981 [==============================] - 36s 36ms/step - loss: 0.0649 - accuracy: 0.9821 - val_loss: 0.1309 - val_accuracy: 0.9713\n",
            "Epoch 7/10\n",
            "981/981 [==============================] - 36s 36ms/step - loss: 0.0539 - accuracy: 0.9856 - val_loss: 0.1209 - val_accuracy: 0.9733\n",
            "Epoch 8/10\n",
            "981/981 [==============================] - 34s 35ms/step - loss: 0.0439 - accuracy: 0.9889 - val_loss: 0.1203 - val_accuracy: 0.9753\n",
            "Epoch 9/10\n",
            "981/981 [==============================] - 34s 35ms/step - loss: 0.0448 - accuracy: 0.9881 - val_loss: 0.1226 - val_accuracy: 0.9759\n",
            "Epoch 10/10\n",
            "981/981 [==============================] - 33s 34ms/step - loss: 0.0259 - accuracy: 0.9930 - val_loss: 0.1521 - val_accuracy: 0.9691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ==============================================================================\n",
        "#\n",
        "# BASIC DATASETS QUESTION\n",
        "#\n",
        "# Create a classifier for the German Traffic Signs dataset that classifies\n",
        "# images of traffic signs into 43 classes.\n",
        "# ==============================================================================\n",
        "#\n",
        "# ABOUT THE DATASET\n",
        "#\n",
        "# The dataset contains traffic sign boards from the streets captured into\n",
        "# image files. There are 43 unique classes in total. The images are of shape\n",
        "# (30,30,3).\n",
        "# ==============================================================================\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "# We have already divided the data for training and validation.\n",
        "#\n",
        "# Complete the code in following functions:\n",
        "# 1. preprocess()\n",
        "# 2. solution_model()\n",
        "#\n",
        "# Your code will fail to be graded if the following criteria are not met:\n",
        "# 1. The input shape of your model must be (30,30,3), because the testing\n",
        "#    infrastructure expects inputs according to this specification.\n",
        "# 2. The last layer of your model must be a Dense layer with 43 neurons\n",
        "#    activated by softmax since this dataset has 43 classes.\n",
        "#\n",
        "# HINT: Your neural network must have a validation accuracy of approximately\n",
        "# 0.95 or above on the normalized validation dataset for top marks.\n",
        "\n",
        "import urllib\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "\n",
        "# This function downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change https to http)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/germantrafficsigns.zip'\n",
        "    urllib.request.urlretrieve(url, 'germantrafficsigns.zip')\n",
        "    with zipfile.ZipFile('germantrafficsigns.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "# COMPLETE THE CODE IN THIS FUNCTION\n",
        "def preprocess(image, label):\n",
        "    # NORMALIZE YOUR IMAGES HERE (HINT: Rescale by 1/.255)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = image / 255.0\n",
        "\n",
        "    return image, label\n",
        "\n",
        "\n",
        "# This function loads the data, normalizes and resizes the images, splits it into\n",
        "# train and validation sets, defines the model, compiles it and finally\n",
        "# trains the model. The trained model is returned from this function.\n",
        "\n",
        "# COMPLETE THE CODE IN THIS FUNCTION.\n",
        "def solution_model():\n",
        "    # Downloads and extracts the dataset to the directory that\n",
        "    # contains this file.\n",
        "    download_and_extract_data()\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    IMG_SIZE = 30\n",
        "\n",
        "    # The following code reads the training and validation data from their\n",
        "    # respective directories, resizes them into the specified image size\n",
        "    # and splits them into batches. You must fill in the image_size\n",
        "    # argument for both training and validation data.\n",
        "    # HINT: Image size is a tuple\n",
        "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory='train/',\n",
        "        label_mode='categorical',\n",
        "        image_size=  (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = BATCH_SIZE)\n",
        "\n",
        "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        directory='validation/',\n",
        "        label_mode='categorical',\n",
        "        image_size=  (IMG_SIZE, IMG_SIZE),\n",
        "        batch_size = BATCH_SIZE)\n",
        "\n",
        "    # Normalizes train and validation datasets using the\n",
        "    # preprocess() function.\n",
        "    # Also makes other calls, as evident from the code, to prepare them for\n",
        "    # training.\n",
        "    # Do not batch or resize the images in the dataset here since it's already\n",
        "    # been done previously.\n",
        "\n",
        "    train_ds = train_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE).prefetch(\n",
        "        tf.data.experimental.AUTOTUNE)\n",
        "    val_ds = val_ds.map(\n",
        "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # Code to define the model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # ADD LAYERS OF THE MODEL HERE\n",
        "\n",
        "        # If you don't adhere to the instructions in the following comments,\n",
        "        # tests will fail to grade your model:\n",
        "        # The input layer of your model must have an input shape of\n",
        "        # (30,30,3).\n",
        "        # Make sure your last layer has 43 neurons activated by softmax.\n",
        "        tf.keras.layers.Input(shape=(30, 30, 3)),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(43, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "    # Code to compile and train the model\n",
        "    model.compile(\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "        train_ds,\n",
        "        validation_data=val_ds,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"mymodel.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_swcqkOA5BuS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}